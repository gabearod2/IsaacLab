--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add/rm <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	deleted:    source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/__init__.py
	deleted:    source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/__init__.py
	deleted:    source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/rsl_rl_cfg.py
	deleted:    source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/skrl_flat_ppo_cfg.yaml
	deleted:    source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/skrl_rough_ppo_cfg.yaml
	deleted:    source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/flat_env_cfg.py
	deleted:    source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/rough_env_cfg.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	logs/rsl_rl/unitree_go2_flat/2024-09-26_15-49-19/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/__init__.py b/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/__init__.py
deleted file mode 100644
index fb502943..00000000
--- a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/__init__.py
+++ /dev/null
@@ -1,55 +0,0 @@
-# Copyright (c) 2022-2024, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-import gymnasium as gym
-
-from . import agents, flat_env_cfg, rough_env_cfg
-
-##
-# Register Gym environments.
-##
-
-gym.register(
-    id="Isaac-Velocity-Flat-Anymal-B-v0",
-    entry_point="omni.isaac.lab.envs:ManagerBasedRLEnv",
-    disable_env_checker=True,
-    kwargs={
-        "env_cfg_entry_point": flat_env_cfg.AnymalBFlatEnvCfg,
-        "rsl_rl_cfg_entry_point": agents.rsl_rl_cfg.AnymalBFlatPPORunnerCfg,
-        "skrl_cfg_entry_point": f"{agents.__name__}:skrl_flat_ppo_cfg.yaml",
-    },
-)
-
-gym.register(
-    id="Isaac-Velocity-Flat-Anymal-B-Play-v0",
-    entry_point="omni.isaac.lab.envs:ManagerBasedRLEnv",
-    disable_env_checker=True,
-    kwargs={
-        "env_cfg_entry_point": flat_env_cfg.AnymalBFlatEnvCfg_PLAY,
-        "rsl_rl_cfg_entry_point": agents.rsl_rl_cfg.AnymalBFlatPPORunnerCfg,
-        "skrl_cfg_entry_point": f"{agents.__name__}:skrl_flat_ppo_cfg.yaml",
-    },
-)
-
-gym.register(
-    id="Isaac-Velocity-Rough-Anymal-B-v0",
-    entry_point="omni.isaac.lab.envs:ManagerBasedRLEnv",
-    disable_env_checker=True,
-    kwargs={
-        "env_cfg_entry_point": rough_env_cfg.AnymalBRoughEnvCfg,
-        "rsl_rl_cfg_entry_point": agents.rsl_rl_cfg.AnymalBRoughPPORunnerCfg,
-        "skrl_cfg_entry_point": f"{agents.__name__}:skrl_rough_ppo_cfg.yaml",
-    },
-)
-
-gym.register(
-    id="Isaac-Velocity-Rough-Anymal-B-Play-v0",
-    entry_point="omni.isaac.lab.envs:ManagerBasedRLEnv",
-    disable_env_checker=True,
-    kwargs={
-        "env_cfg_entry_point": rough_env_cfg.AnymalBRoughEnvCfg_PLAY,
-        "rsl_rl_cfg_entry_point": agents.rsl_rl_cfg.AnymalBRoughPPORunnerCfg,
-        "skrl_cfg_entry_point": f"{agents.__name__}:skrl_rough_ppo_cfg.yaml",
-    },
-)
diff --git a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/__init__.py b/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/__init__.py
deleted file mode 100644
index b3a5a970..00000000
--- a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/__init__.py
+++ /dev/null
@@ -1,6 +0,0 @@
-# Copyright (c) 2022-2024, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from . import rsl_rl_cfg  # noqa: F401, F403
diff --git a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/rsl_rl_cfg.py b/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/rsl_rl_cfg.py
deleted file mode 100644
index 1802b426..00000000
--- a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/rsl_rl_cfg.py
+++ /dev/null
@@ -1,52 +0,0 @@
-# Copyright (c) 2022-2024, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from omni.isaac.lab.utils import configclass
-
-from omni.isaac.lab_tasks.utils.wrappers.rsl_rl import (
-    RslRlOnPolicyRunnerCfg,
-    RslRlPpoActorCriticCfg,
-    RslRlPpoAlgorithmCfg,
-)
-
-
-@configclass
-class AnymalBRoughPPORunnerCfg(RslRlOnPolicyRunnerCfg):
-    num_steps_per_env = 24
-    max_iterations = 1500
-    save_interval = 50
-    experiment_name = "anymal_b_rough"
-    empirical_normalization = False
-    policy = RslRlPpoActorCriticCfg(
-        init_noise_std=1.0,
-        actor_hidden_dims=[512, 256, 128],
-        critic_hidden_dims=[512, 256, 128],
-        activation="elu",
-    )
-    algorithm = RslRlPpoAlgorithmCfg(
-        value_loss_coef=1.0,
-        use_clipped_value_loss=True,
-        clip_param=0.2,
-        entropy_coef=0.005,
-        num_learning_epochs=5,
-        num_mini_batches=4,
-        learning_rate=1.0e-3,
-        schedule="adaptive",
-        gamma=0.99,
-        lam=0.95,
-        desired_kl=0.01,
-        max_grad_norm=1.0,
-    )
-
-
-@configclass
-class AnymalBFlatPPORunnerCfg(AnymalBRoughPPORunnerCfg):
-    def __post_init__(self):
-        super().__post_init__()
-
-        self.max_iterations = 300
-        self.experiment_name = "anymal_b_flat"
-        self.policy.actor_hidden_dims = [128, 128, 128]
-        self.policy.critic_hidden_dims = [128, 128, 128]
diff --git a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/skrl_flat_ppo_cfg.yaml b/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/skrl_flat_ppo_cfg.yaml
deleted file mode 100644
index 8a3c4dc2..00000000
--- a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/skrl_flat_ppo_cfg.yaml
+++ /dev/null
@@ -1,67 +0,0 @@
-seed: 42
-
-# Models are instantiated using skrl's model instantiator utility
-# https://skrl.readthedocs.io/en/latest/api/utils/model_instantiators.html
-models:
-  separate: False
-  policy:  # see skrl.utils.model_instantiators.torch.gaussian_model for parameter details
-    clip_actions: True
-    clip_log_std: True
-    initial_log_std: 0
-    min_log_std: -20.0
-    max_log_std: 2.0
-    input_shape: "Shape.STATES"
-    hiddens: [128, 128, 128]
-    hidden_activation: ["elu", "elu"]
-    output_shape: "Shape.ACTIONS"
-    output_activation: ""
-    output_scale: 1.0
-  value:  # see skrl.utils.model_instantiators.torch.deterministic_model for parameter details
-    clip_actions: False
-    input_shape: "Shape.STATES"
-    hiddens: [128, 128, 128]
-    hidden_activation: ["elu", "elu"]
-    output_shape: "Shape.ONE"
-    output_activation: ""
-    output_scale: 1.0
-
-
-# PPO agent configuration (field names are from PPO_DEFAULT_CONFIG)
-# https://skrl.readthedocs.io/en/latest/api/agents/ppo.html
-agent:
-  rollouts: 24
-  learning_epochs: 5
-  mini_batches: 4
-  discount_factor: 0.99
-  lambda: 0.95
-  learning_rate: 1.e-3
-  learning_rate_scheduler: "KLAdaptiveLR"
-  learning_rate_scheduler_kwargs:
-    kl_threshold: 0.01
-  state_preprocessor: "RunningStandardScaler"
-  state_preprocessor_kwargs: null
-  value_preprocessor: "RunningStandardScaler"
-  value_preprocessor_kwargs: null
-  random_timesteps: 0
-  learning_starts: 0
-  grad_norm_clip: 1.0
-  ratio_clip: 0.2
-  value_clip: 0.2
-  clip_predicted_values: True
-  entropy_loss_scale: 0.005
-  value_loss_scale: 1.0
-  kl_threshold: 0
-  rewards_shaper_scale: 1.0
-  # logging and checkpoint
-  experiment:
-    directory: "anymal_b_flat"
-    experiment_name: ""
-    write_interval: 36
-    checkpoint_interval: 360
-
-
-# Sequential trainer
-# https://skrl.readthedocs.io/en/latest/api/trainers/sequential.html
-trainer:
-  timesteps: 7200
-  environment_info: "log"
diff --git a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/skrl_rough_ppo_cfg.yaml b/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/skrl_rough_ppo_cfg.yaml
deleted file mode 100644
index 54835c25..00000000
--- a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/agents/skrl_rough_ppo_cfg.yaml
+++ /dev/null
@@ -1,67 +0,0 @@
-seed: 42
-
-# Models are instantiated using skrl's model instantiator utility
-# https://skrl.readthedocs.io/en/latest/api/utils/model_instantiators.html
-models:
-  separate: False
-  policy:  # see skrl.utils.model_instantiators.torch.gaussian_model for parameter details
-    clip_actions: True
-    clip_log_std: True
-    initial_log_std: 0
-    min_log_std: -20.0
-    max_log_std: 2.0
-    input_shape: "Shape.STATES"
-    hiddens: [512, 256, 128]
-    hidden_activation: ["elu", "elu"]
-    output_shape: "Shape.ACTIONS"
-    output_activation: ""
-    output_scale: 1.0
-  value:  # see skrl.utils.model_instantiators.torch.deterministic_model for parameter details
-    clip_actions: False
-    input_shape: "Shape.STATES"
-    hiddens: [512, 256, 128]
-    hidden_activation: ["elu", "elu"]
-    output_shape: "Shape.ONE"
-    output_activation: ""
-    output_scale: 1.0
-
-
-# PPO agent configuration (field names are from PPO_DEFAULT_CONFIG)
-# https://skrl.readthedocs.io/en/latest/api/agents/ppo.html
-agent:
-  rollouts: 24
-  learning_epochs: 5
-  mini_batches: 4
-  discount_factor: 0.99
-  lambda: 0.95
-  learning_rate: 1.e-3
-  learning_rate_scheduler: "KLAdaptiveLR"
-  learning_rate_scheduler_kwargs:
-    kl_threshold: 0.01
-  state_preprocessor: "RunningStandardScaler"
-  state_preprocessor_kwargs: null
-  value_preprocessor: "RunningStandardScaler"
-  value_preprocessor_kwargs: null
-  random_timesteps: 0
-  learning_starts: 0
-  grad_norm_clip: 1.0
-  ratio_clip: 0.2
-  value_clip: 0.2
-  clip_predicted_values: True
-  entropy_loss_scale: 0.005
-  value_loss_scale: 1.0
-  kl_threshold: 0
-  rewards_shaper_scale: 1.0
-  # logging and checkpoint
-  experiment:
-    directory: "anymal_b_rough"
-    experiment_name: ""
-    write_interval: 180
-    checkpoint_interval: 1800
-
-
-# Sequential trainer
-# https://skrl.readthedocs.io/en/latest/api/trainers/sequential.html
-trainer:
-  timesteps: 36000
-  environment_info: "log"
diff --git a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/flat_env_cfg.py b/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/flat_env_cfg.py
deleted file mode 100644
index 9e783d51..00000000
--- a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/flat_env_cfg.py
+++ /dev/null
@@ -1,43 +0,0 @@
-# Copyright (c) 2022-2024, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from omni.isaac.lab.utils import configclass
-
-from .rough_env_cfg import AnymalBRoughEnvCfg
-
-
-@configclass
-class AnymalBFlatEnvCfg(AnymalBRoughEnvCfg):
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-
-        # override rewards
-        self.rewards.flat_orientation_l2.weight = -5.0
-        self.rewards.dof_torques_l2.weight = -2.5e-5
-        self.rewards.feet_air_time.weight = 0.5
-        # change terrain to flat
-        self.scene.terrain.terrain_type = "plane"
-        self.scene.terrain.terrain_generator = None
-        # no height scan
-        self.scene.height_scanner = None
-        self.observations.policy.height_scan = None
-        # no terrain curriculum
-        self.curriculum.terrain_levels = None
-
-
-class AnymalBFlatEnvCfg_PLAY(AnymalBFlatEnvCfg):
-    def __post_init__(self) -> None:
-        # post init of parent
-        super().__post_init__()
-
-        # make a smaller scene for play
-        self.scene.num_envs = 50
-        self.scene.env_spacing = 2.5
-        # disable randomization for play
-        self.observations.policy.enable_corruption = False
-        # remove random pushing event
-        self.events.base_external_force_torque = None
-        self.events.push_robot = None
diff --git a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/rough_env_cfg.py b/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/rough_env_cfg.py
deleted file mode 100644
index 31c6219b..00000000
--- a/source/extensions/omni.isaac.lab_tasks/omni/isaac/lab_tasks/manager_based/locomotion/velocity/config/anymal_b/rough_env_cfg.py
+++ /dev/null
@@ -1,46 +0,0 @@
-# Copyright (c) 2022-2024, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from omni.isaac.lab.utils import configclass
-
-from omni.isaac.lab_tasks.manager_based.locomotion.velocity.velocity_env_cfg import LocomotionVelocityRoughEnvCfg
-
-##
-# Pre-defined configs
-##
-from omni.isaac.lab_assets import ANYMAL_B_CFG  # isort: skip
-
-
-@configclass
-class AnymalBRoughEnvCfg(LocomotionVelocityRoughEnvCfg):
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-        # switch robot to anymal-d
-        self.scene.robot = ANYMAL_B_CFG.replace(prim_path="{ENV_REGEX_NS}/Robot")
-
-
-@configclass
-class AnymalBRoughEnvCfg_PLAY(AnymalBRoughEnvCfg):
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-
-        # make a smaller scene for play
-        self.scene.num_envs = 50
-        self.scene.env_spacing = 2.5
-        # spawn the robot randomly in the grid (instead of their terrain levels)
-        self.scene.terrain.max_init_terrain_level = None
-        # reduce the number of terrains to save memory
-        if self.scene.terrain.terrain_generator is not None:
-            self.scene.terrain.terrain_generator.num_rows = 5
-            self.scene.terrain.terrain_generator.num_cols = 5
-            self.scene.terrain.terrain_generator.curriculum = False
-
-        # disable randomization for play
-        self.observations.policy.enable_corruption = False
-        # remove random pushing event
-        self.events.base_external_force_torque = None
-        self.events.push_robot = None